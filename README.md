# Easy-VQA
Easy VQA: Deep Learning Model for Visual Question Answering
This repository contains code for a deep learning model trained on the Easy Visual Question Answering (VQA) Dataset by VictorZhou. The model achieves almost 99% accuracy on the validation set and uses convolutional layers for image input and LSTM layer for text input to provide a relevant text output.

## About Visual Question Answering
Visual question answering is a challenging task that involves answering natural language questions about images. The goal is to build models that can not only recognize objects and scenes in images, but also understand the meaning of questions and provide accurate answers.

VQA has become an important research topic in both computer vision and natural language processing, and has many real-world applications, such as in robotics, autonomous vehicles, and virtual assistants.

## Installation
To use this code, you will need to have Python 3 installed, along with the following packages:

- TensorFlow
- NumPy
- Matplotlib

You can install these packages using pip. For example:

`pip install tensorflow numpy matplotlib`

To see the results, visit my kaggle notebook: 

## Future Work
While the current model performs well, there are several areas for improvement. One potential avenue for improvement is to explore different architectures and hyperparameters to see if the performance can be further improved. Additionally, it may be useful to investigate the use of pre-trained models or transfer learning to improve the model's performance on more complex datasets.

## Acknowledgments
I would like to thank VictorZhou for providing the Easy VQA dataset and the inspiration for this project.
